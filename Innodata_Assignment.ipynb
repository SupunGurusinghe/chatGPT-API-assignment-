{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNi8cLgSvw1IWTpTBr0s7JJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SupunGurusinghe/chatGPT-API-assignment-/blob/main/Innodata_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **First phase of the assignment**"
      ],
      "metadata": {
        "id": "hpR1fZS3FbcU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install the OpenAI Python package to access the GPT-3 API**"
      ],
      "metadata": {
        "id": "0IMQmRnLQWie"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG1QyXAuNsK7",
        "outputId": "d93f0f02-bff3-41dc-8400-cdb678966da6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import the necessary modules in your Python script**"
      ],
      "metadata": {
        "id": "JwqkFkWWQimu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json"
      ],
      "metadata": {
        "id": "U1sqvn1SN0v2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Authenticate with OpenAI using your API key**"
      ],
      "metadata": {
        "id": "P2l5DoQIQoqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\""
      ],
      "metadata": {
        "id": "pruUHHd3OIvB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the text of the research paper you want to analyze**"
      ],
      "metadata": {
        "id": "lGwM9g-2Qvmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Named Entity Recognition\n",
        "March 2014\n",
        "DOI: 10.1007/978-3-642-45358-8_7\n",
        "In book: Natural Language Processing of Semitic Languages\n",
        "Behrang Mohit\"\"\""
      ],
      "metadata": {
        "id": "qyQTMSQ7ONjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the prompts to extract specific information from the text**"
      ],
      "metadata": {
        "id": "Ode09U4FQzam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title_prompt = \"What is the title of the paper?\""
      ],
      "metadata": {
        "id": "aK_8jXckOvV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use the OpenAI API to generate the text for each prompt**"
      ],
      "metadata": {
        "id": "N3FdmHakRyac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title_response = openai.Completion.create(\n",
        "    engine=\"text-davinci-002\",\n",
        "    prompt=title_prompt + \"\\nText: \" + text,\n",
        "    temperature=0.5,\n",
        "    max_tokens=200,\n",
        "    n = 1,\n",
        "    stop=None,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0\n",
        ")"
      ],
      "metadata": {
        "id": "Pe3UexfeO1Lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parse the response from the OpenAI API and extract the relevant information**"
      ],
      "metadata": {
        "id": "nGl7aP6WQ6ZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title = title_response.choices[0].text.strip()"
      ],
      "metadata": {
        "id": "lBlfeaSZO4xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Print extracted information**"
      ],
      "metadata": {
        "id": "xXXjcM0yR92f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k34kFIPxp2hI",
        "outputId": "ae4ddecd-b8a3-4cd3-aacb-b23cd8ea4067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The title of the paper is \"Named Entity Recognition.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write the extracted information to a JSON file**"
      ],
      "metadata": {
        "id": "GBAtgzUzSW-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"title\": title,\n",
        "    # \"authors\": authors,\n",
        "    # Add additional fields as needed\n",
        "}\n",
        "\n",
        "with open(\"output.json\", \"w\") as outfile:\n",
        "    json.dump(data, outfile, indent=4)\n"
      ],
      "metadata": {
        "id": "b874I0wVQQHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Iterate the process**"
      ],
      "metadata": {
        "id": "WLOUUd8pp8ZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What is the title of the paper. Who is the author.\"\n",
        "prompt_list = prompt.split(\". \")\n",
        "\n",
        "data = {}\n",
        "\n",
        "for prompt_txt in prompt_list:\n",
        "  details_response = openai.Completion.create(\n",
        "    engine=\"text-davinci-002\",\n",
        "    prompt=prompt_txt + \"\\nText: \" + text,\n",
        "    temperature=0.5,\n",
        "    max_tokens=200,\n",
        "    n = 1,\n",
        "    stop=None,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0\n",
        "  )  \n",
        "  details = details_response.choices[0].text.strip()\n",
        "  print(details)\n",
        "\n",
        "  data[prompt_txt] = details\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lMHbmESqA3A",
        "outputId": "baa1d9ae-6b6d-4634-b487-8a9cc31f602d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The title of the paper is \"Named Entity Recognition.\"\n",
            "Behrang Mohit is the author.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"output.json\", \"w\") as outfile:\n",
        "    json.dump(data, outfile, indent=4)"
      ],
      "metadata": {
        "id": "TKQyKje1rw-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Second phase of the assignment - for pdf characters < 4096**"
      ],
      "metadata": {
        "id": "aNQgNImGFUEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9TyVORkFW-M",
        "outputId": "c8b2b133-26d8-4481-8498-19c7379ec7f9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.9/dist-packages (from PyPDF2) (4.5.0)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "6ElsatujFovg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "FiOjt0DjFu9f",
        "outputId": "30f12945-414f-4a77-f0df-329fd51d997e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-afe21ef5-12c3-46e5-b919-7aea2679b946\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-afe21ef5-12c3-46e5-b919-7aea2679b946\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving How_to_Summarize_a_Research_Article1.pdf to How_to_Summarize_a_Research_Article1.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in uploaded.keys():\n",
        "    with open(filename, 'rb') as pdf_file:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        num_pages = len(pdf_reader.pages)\n",
        "\n",
        "        text = ''\n",
        "        for page in range(num_pages):\n",
        "            page_obj = pdf_reader.pages[page]\n",
        "            text += page_obj.extract_text()\n",
        "\n",
        "        pdf_file.close()"
      ],
      "metadata": {
        "id": "_g5vJTvVFw7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What is the title of this text. Who is the author of this text. What are the sub topics in this text.\"\n",
        "prompt_list = prompt.split(\". \")\n",
        "\n",
        "data = {}\n",
        "\n",
        "for prompt_txt in prompt_list:\n",
        "  details_response = openai.Completion.create(\n",
        "    engine=\"text-davinci-002\",\n",
        "    prompt=prompt_txt + \"\\nText: \" + text,\n",
        "    temperature=0.5,\n",
        "    max_tokens=200,\n",
        "    n = 1,\n",
        "    stop=None,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0\n",
        "  )  \n",
        "  details = details_response.choices[0].text.strip()\n",
        "  print(details)\n",
        "\n",
        "  data[prompt_txt] = details"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBqRP7__GmcF",
        "outputId": "5d0fdf6a-c2ed-4da9-fb02-a13b7ac3e193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarizing a Research Article\n",
            "The author of the text is unknown.\n",
            "The sub topics in this text are: \n",
            "- How to Summarize a Research Article \n",
            "- Determining Your Focus \n",
            "- Reading the Article \n",
            "- Writing the Summary \n",
            "- Editing for Completeness and Accuracy \n",
            "- Editing for Style\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"output.json\", \"w\") as outfile:\n",
        "    json.dump(data, outfile, indent=4)"
      ],
      "metadata": {
        "id": "XBHhCeCsJmgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Third phase of the assignment - for pdf characters > 4096**"
      ],
      "metadata": {
        "id": "obUiH3EOClMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "i66lCh0zTn07"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pdf_to_text(uploaded):\n",
        "  for filename in uploaded.keys():\n",
        "      with open(filename, 'rb') as pdf_file:\n",
        "          pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "          num_pages = len(pdf_reader.pages)\n",
        "\n",
        "          text = ''\n",
        "          for page in range(num_pages):\n",
        "              page_obj = pdf_reader.pages[page]\n",
        "              text += page_obj.extract_text()\n",
        "\n",
        "          pdf_file.close()\n",
        "  return text"
      ],
      "metadata": {
        "id": "cRI7IBsIMab0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the long input text into smaller chunks that are each within the maximum context length\n",
        "def split_by_smaller_chunks(text, MAX_TOKENS_PER_REQUEST = 4000):\n",
        "  input_chunks = [text[i:i+2048] for i in range(0, len(text), MAX_TOKENS_PER_REQUEST)]\n",
        "  return input_chunks"
      ],
      "metadata": {
        "id": "V5CeFhUCV4ur"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the input text into sentences\n",
        "def split_by_sentence(text, MAX_TOKENS_PER_REQUEST = 4000):\n",
        "  sentences = re.split('(?<=\\w\\.) ', text)\n",
        "\n",
        "  input_chunks = []\n",
        "  chunk = ''\n",
        "  for sentence in sentences:\n",
        "      if len(chunk) + len(sentence) < MAX_TOKENS_PER_REQUEST:\n",
        "          chunk += sentence\n",
        "      else:\n",
        "          input_chunks.append(chunk)\n",
        "          chunk = sentence\n",
        "\n",
        "  # Add the last chunk to the list\n",
        "  if chunk:\n",
        "      input_chunks.append(chunk)\n",
        "\n",
        "  return input_chunks"
      ],
      "metadata": {
        "id": "PSprKlrvVBrd"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the input text into paragraphs\n",
        "def split_by_paragraph(text, MAX_TOKENS_PER_REQUEST = 4000):\n",
        "  paragraphs = text.split(\"\\n\\n\")\n",
        "\n",
        "  input_chunks = []\n",
        "  chunk = ''\n",
        "  for paragraph in paragraphs:\n",
        "      if len(chunk) + len(paragraph) < MAX_TOKENS_PER_REQUEST:\n",
        "          chunk += paragraph\n",
        "      else:\n",
        "          input_chunks.append(chunk)\n",
        "          chunk = paragraph\n",
        "\n",
        "  # Add the last chunk to the list\n",
        "  if chunk:\n",
        "      input_chunks.append(chunk)\n",
        "\n",
        "  return input_chunks"
      ],
      "metadata": {
        "id": "n5w0ObZ_VqZy"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def openai_response(context, max_output_length=200, temperature=0.7, n=1, frequency_penalty=0, presence_penalty=0):\n",
        "  # Generate the output using the GPT-3 API\n",
        "  response = openai.Completion.create(\n",
        "      engine=\"text-davinci-003\",\n",
        "      prompt=context,\n",
        "      max_tokens=max_output_length,\n",
        "      temperature=0.7,\n",
        "      n = 1,\n",
        "      stop=None,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0\n",
        "  )\n",
        "  return response"
      ],
      "metadata": {
        "id": "d8GcQvl0NVzI"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(text, prompt, method, MAX_TOKENS_PER_REQUEST = 4000, max_output_length=200, temperature=0.7, n=1, frequency_penalty=0, presence_penalty=0):\n",
        "  if method == \"split_by_smaller_chunks\":\n",
        "    input_chunks = split_by_smaller_chunks(text, MAX_TOKENS_PER_REQUEST = 4000)\n",
        "  elif method == \"split_by_sentence\":\n",
        "    input_chunks = split_by_sentence(text, MAX_TOKENS_PER_REQUEST = 4000)\n",
        "  elif method == \"split_by_paragraph\":\n",
        "    input_chunks = split_by_paragraph(text, MAX_TOKENS_PER_REQUEST = 4000)\n",
        "  else:\n",
        "    input_chunks = split_by_sentence(text, MAX_TOKENS_PER_REQUEST = 4000)\n",
        "\n",
        "  results = []\n",
        "\n",
        "  # Loop through the input chunks and generate an output for each one\n",
        "  for chunk in input_chunks:\n",
        "\n",
        "    for prompt_txt in prompt:\n",
        "      # Concatenate the input chunk and prompt into a single string\n",
        "      context = prompt_txt + \"\\nText: \" + chunk\n",
        "\n",
        "      # Generate the output using the GPT-3 API\n",
        "      response = openai_response(context, max_output_length, temperature, n, frequency_penalty, presence_penalty)\n",
        "\n",
        "      results.append(response.choices[0].text.strip())\n",
        "  return results\n"
      ],
      "metadata": {
        "id": "DA-p4ugJCvo-"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "text = pdf_to_text(uploaded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "8vOeTmAKEa6A",
        "outputId": "8227aa19-4a6d-43f3-b2c6-f614fee59c44"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-be4a9897-eb4b-4e07-8988-12928541c4db\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-be4a9897-eb4b-4e07-8988-12928541c4db\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving How_to_Summarize_a_Research_Article1.pdf to How_to_Summarize_a_Research_Article1.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp9mnQkVAN8Q",
        "outputId": "a17b528c-f6dd-4d89-8a18-c9abdd921f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.9/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from bs4) (4.9.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->bs4) (2.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#@title **Add Text for Web Articles and Blogs**\n",
        "\n",
        "url = \"https://en.wikipedia.org/wiki/Medium_(website)\" #@param {type:\"string\"}\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "text = soup.get_text()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0kJJsWHuATuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Enter a Prompt List**\n",
        "Prompt = [\"This article is published by who?\", \"Who are the group members of this?\"] #@param {type:\"raw\"}\n",
        "method = \"split_by_sentence\" #@param [\"split_by_smaller_chunks\", \"split_by_sentence\", \"split_by_paragraph\"]\n",
        "MAX_TOKENS_PER_REQUEST = 4000 #@param {type:\"number\"}\n",
        "\n",
        "if type(Prompt) == list:\n",
        "  results = generate_response(text, Prompt, method=split_by_sentence)\n",
        "  print(\"Intermediate Results \\n========================\\n\")\n",
        "  for res in range(0, len(results)):\n",
        "    print(results[res])\n",
        "    \n",
        "  # join outputs\n",
        "  s = \"\\n\"\n",
        "  results = s.join(results)\n",
        "\n",
        "  data = {}\n",
        "  for prompt_txt in Prompt:\n",
        "    # Concatenate the input chunk and prompt into a single string\n",
        "    context = prompt_txt + \"\\nText: \" + results\n",
        "\n",
        "    # Generate the output using the GPT-3 API\n",
        "    response = openai_response(context)\n",
        "    data[prompt_txt] = response.choices[0].text.strip()\n",
        "\n",
        "  print(\"\\n\\nFinal Results \\n========================\\n\")\n",
        "  for key, val in data.items():\n",
        "    print(f\"{key}: {val}\")\n",
        "else:\n",
        "  print(\"Enter a python list to the prompt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcIrNMnBEeTw",
        "outputId": "017b055d-ba06-4bdd-e6bc-1f771d5aa69a",
        "cellView": "form"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intermediate Results \n",
            "========================\n",
            "\n",
            "1.1 Uses of Plastic \n",
            "Plastic products have proven to be a great help for humans in many ways. It is used for \n",
            "packaging of food , for making medical equipment , for carrying water , for making \n",
            "automobiles, for making toys and many other products . \n",
            " \n",
            "1.2 Plastic as a material is not a problem; but how we manage it is an issue  \n",
            "Plastic is a very useful material and can be recycled and reused.But plastic is a non- \n",
            "biodegradable material. It takes hundreds of years to decompose and leaves behind toxic \n",
            "chemicals that pollute soil and water bodies.This means that the plastic that is disposed of \n",
            "remains in the environment for a long time if not managed properly. This is why plastic \n",
            "pollution has become a major environmental concern . Introduction to Plastic  Pollution   \n",
            "2 \n",
            "\n",
            "When plastic is not managed properly\n",
            "1.1 Uses of Plastic  \n",
            "Plastics are used in many types of products – from children’s toys to medical equipment. Some \n",
            "of the common uses of plastic are: \n",
            "•\tFood and Beverage Containers \n",
            "•\tPackaging material \n",
            "•\tCarry bags \n",
            "•\tFurniture \n",
            "•\tElectronic gadgets \n",
            "•\tClothing \n",
            "•\tMedical equipment \n",
            "•\tCosmetic containers \n",
            "•\tAutomobile components \n",
            "•\tToys \n",
            "Introduction to Plastic  Pollution   \n",
            "2 \n",
            "•\tConstruction material \n",
            "•\tStationery \n",
            "•\tHome appliances \n",
            "•\tComputer parts \n",
            " \n",
            "1.2 Plastic as a material is not a problem; but how we manage it is an issue  \n",
            "Plastic is not a problem as such; but the way it is managed and disposed is a matter of concern. \n",
            "The\n",
            "These animals die due to suffocation and or starvation as the plastic materials block \n",
            "their digestive tracts or stomachs. \n",
            "\n",
            "This article is published by Introduction to Plastic Pollution.\n",
            "The group members of this are not specified.\n",
            "5.Repair - Instead of throwing away broken plastic products, try to repair them.This will help \n",
            "in reducing plastic pollution.\n",
            "\n",
            "This article is published by WWF Australia.\n",
            "In some areas, \n",
            "waste collectors come in their vehicles to collect recyclable wastes from our homes.  \n",
            "5.Remove - remove plastic from the streets and other public places. We can also organise \n",
            "clean-up drives in our local areas.  \n",
            "\n",
            "The group members of this would be anyone who is interested in helping to manage plastic pollution.\n",
            "Organising  workshops on Plastic pollution  \n",
            "2.Conducting  plastic waste management drives  \n",
            "3.Creating  of visual art to sensitize people on plastic pollution  \n",
            "4.Involving  citizens to make use of alternatives to plastic \n",
            "\n",
            "This article is published by The Energy and Resources Institute (TERI).\n",
            "Awareness walk \n",
            "2.House visits \n",
            "3.Interactive sessions \n",
            "4.Workshops \n",
            "\n",
            "The group members of the campaign are The Energy and Resources Institute (TERI), United Nations Environment Programme (UNEP), Helen Keller Institute for Deaf and Deaf blind, Navi Mumbai, local communities, and youth.\n",
            "This article is published by The Energy and Resources Institute (TERI).\n",
            "Group Members: \n",
            "1. The Energy and Resources Institute (TERI) \n",
            "2. United Nations Environment Programme (UNEP) \n",
            "3. National Service Scheme (NSS) \n",
            "4. Thane Belapur Industries Association \n",
            "5. Various Colleges \n",
            "6. More than 1000 people who have taken the pledge against single-use plastics \n",
            "7. More than 800 respondents from the perception survey\n",
            "\n",
            "\n",
            "Final Results \n",
            "========================\n",
            "\n",
            "This article is published by who?: 8. Various local communities \n",
            "9. Youth\n",
            "Who are the group members of this?: 8. Local communities and youth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"results.json\", \"w\") as outfile:\n",
        "    json.dump(data, outfile, indent=4)"
      ],
      "metadata": {
        "id": "7Ung3gHpSE1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Change Response Parameters**\n",
        "Prompt = [\"This article is published by who?\", \"Who are the group members of this?\"] #@param {type:\"raw\"}\n",
        "method = \"split_by_sentence\" #@param [\"split_by_smaller_chunks\", \"split_by_sentence\", \"split_by_paragraph\"]\n",
        "max_output_length = 200 #@param {type:\"integer\"}\n",
        "temperature = 0.7 #@param {type:\"number\"}\n",
        "n = 1 #@param {type:\"integer\"}\n",
        "frequency_penalty = 0 #@param {type:\"number\"}\n",
        "presence_penalty = 0 #@param {type:\"number\"}\n",
        "MAX_TOKENS_PER_REQUEST = 4000 #@param {type:\"integer\"}\n",
        "\n",
        "if type(Prompt) == list:\n",
        "  results = generate_response(text, Prompt, method, MAX_TOKENS_PER_REQUEST, max_output_length, temperature, n, frequency_penalty, presence_penalty)\n",
        "  print(\"Intermediate Results \\n========================\\n\")\n",
        "  for res in range(0, len(results)):\n",
        "    print(results[res])\n",
        "    \n",
        "  # join outputs\n",
        "  s = \"\\n\"\n",
        "  results = s.join(results)\n",
        "\n",
        "  data = {}\n",
        "  for prompt_txt in Prompt:\n",
        "    # Concatenate the input chunk and prompt into a single string\n",
        "    context = prompt_txt + \"\\nText: \" + results\n",
        "\n",
        "    # Generate the output using the GPT-3 API\n",
        "    response = openai_response(context, max_output_length, temperature, n, frequency_penalty, presence_penalty)\n",
        "    data[prompt_txt] = response.choices[0].text.strip()\n",
        "    \n",
        "  print(\"\\n\\nFinal Results \\n========================\\n\")\n",
        "  for key, val in data.items():\n",
        "    print(f\"{key}: {val}\")\n",
        "else:\n",
        "  print(\"Enter a python list to the prompt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "aBCLnqPtb3K7",
        "outputId": "156ec88e-1753-4b92-d36f-84d693fd8f4b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intermediate Results \n",
            "========================\n",
            "\n",
            "1.1 Uses of Plastic  \n",
            "Plastic has great usability in day to day life, whether in the form of rigid or flexible material. \n",
            "It is used in packaging of food, medicines and consumer products. Plastic is also used in \n",
            "manufacturing of cars, boats, machines and other items. It is also used for making medical \n",
            "equipments, toys and electrical fittings. Plastic is used in construction of buildings and \n",
            "infrastructure, furniture and even in agricultural processes.  \n",
            "1.2 Plastic as a Material is not a Problem; but How We Manage it is an Issue  \n",
            "Plastic is an incredibly useful material; however,  the way we manage it has caused the world \n",
            "a great deal of harm. It is estimated that 8 million tons of plastics waste enter the oceans every \n",
            "year. This plastic waste is killing fish, birds and marine animals, and it is contaminating the \n",
            "Introduction to Plastic Pollution\n",
            "1.1  Uses of Plastic \n",
            "Plastics are used in almost all the products that we use and come in contact with. \n",
            " \n",
            "Some of the products that use plastic are listed below –  \n",
            "•\tWater bottles  \n",
            "•\tBags \n",
            "•\tFood and liquid containers \n",
            "•\tToothbrushes and combs  \n",
            "•\tCars and electronic items  \n",
            "•\tFurniture and toys \n",
            "•\tClothing \n",
            "•\tPackaging materials \n",
            "•\tPipes \n",
            "•\tMedical and health products  \n",
            "1.2  Plastic as a material is not a problem; but how we manage it is an issue  \n",
            "Plastic as a material is not a problem; but how we manage it is an issue. Plastic is used in \n",
            "many products and it is difficult to avoid it in day-to-day life. We need to produce and use \n",
            "plastic responsibly\n",
            "This article is published by Introduction to Plastic Pollution.\n",
            "Group Members: None are listed.\n",
            "5.Replac e - Plastic products can be replaced with reus able and biodegradable products. \n",
            "\n",
            "This article is published by WWF Australia.\n",
            "5.Replace - Use biodegradable or reusable alternatives  like bamboo, glass or cloth bags  \n",
            "instead of plastic bags. \n",
            "\n",
            "The group members of this are: \n",
            "1. WWF Australia \n",
            "2. ResearchGate \n",
            "3. NCBI \n",
            "4. Touch and Feel Kit \n",
            "5. Bio-magnification \n",
            "6. Recyclers\n",
            "Carrying out awareness events and workshops to sensitize youth on plastic pollution \n",
            "2.Collection and categorization of plastic waste from various locations \n",
            "3.Cleaning of beaches  \n",
            "4.Demonstration of different technologies for effective reuse/ recycle of plastic \n",
            "5.Demonstration of different alternatives to plastic\n",
            " \n",
            "\n",
            "This article is published by The Energy and Resources Institute (TERI).\n",
            "Awareness programmes \n",
            "2.Engaging local communities \n",
            "3.Cleaning of beaches and other water bodies  \n",
            "\n",
            "The group members of the 'Rethink Plastic' Campaign are TERI, UNEP, Helen Keller Institute for Deaf and Deaf blind, Navi Mumbai, and the local communities.\n",
            "This article is published by The Energy and Resources Institute (TERI).\n",
            "Group Members: \n",
            "1. The Energy and Resources Institute (TERI) \n",
            "2. United Nations Environment Programme (UNEP) \n",
            "3. National Service Scheme (NSS) \n",
            "4. Thane Belapur Industries Association \n",
            "5. Various Colleges \n",
            "6. People who took the pledge against single use plastics\n",
            "\n",
            "\n",
            "Final Results \n",
            "========================\n",
            "\n",
            "This article is published by who?: 7. Local communities\n",
            "Who are the group members of this?: 7. Local Communities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"results.json\", \"w\") as outfile:\n",
        "    json.dump(data, outfile, indent=4)"
      ],
      "metadata": {
        "id": "Q4msApbffKpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment"
      ],
      "metadata": {
        "id": "nbrruvm3OCtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response_2(text, prompt, keywords, method, MAX_TOKENS_PER_REQUEST=4000, max_output_length=200, temperature=0.7, n=1, frequency_penalty=0, presence_penalty=0):\n",
        "  if method == \"split_by_smaller_chunks\":\n",
        "    input_chunks = split_by_smaller_chunks(text, MAX_TOKENS_PER_REQUEST=4000)\n",
        "  elif method == \"split_by_sentence\":\n",
        "    input_chunks = split_by_sentence(text, MAX_TOKENS_PER_REQUEST=4000)\n",
        "  elif method == \"split_by_paragraph\":\n",
        "    input_chunks = split_by_paragraph(text, MAX_TOKENS_PER_REQUEST=4000)\n",
        "  else:\n",
        "    input_chunks = split_by_sentence(text, MAX_TOKENS_PER_REQUEST=4000)\n",
        "\n",
        "  chunk_count = 0\n",
        "  results = []\n",
        "\n",
        "  summary_count = (4096 - len(prompt)) / len(input_chunks)\n",
        "\n",
        "  # Loop through the input chunks and generate an output for each one\n",
        "  for chunk in input_chunks:\n",
        "    chunk_count += 1\n",
        "\n",
        "    # Concatenate the input chunk and prompt into a single string\n",
        "    context = f\"{chunk} \\n\\n Shorten this text by including main points of text having keywords {keywords} and word count less than or equal to a word count of {summary_count}\"\n",
        "    \n",
        "    # Generate the output using the GPT-3 API\n",
        "    response = openai_response(context, max_output_length, temperature, n, frequency_penalty, presence_penalty)\n",
        "\n",
        "    results.append(response.choices[0].text.strip())\n",
        "  return results"
      ],
      "metadata": {
        "id": "ztfBAej5OCVX"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "text = pdf_to_text(uploaded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "F4uREZjPRV72",
        "outputId": "6c60f390-232f-43bf-e5bd-65459b480308"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8f0bb56d-0eab-42bb-b0ca-c12627ca1728\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8f0bb56d-0eab-42bb-b0ca-c12627ca1728\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Annexure_B6_ Braille-Booklet-on-Plastic-Pollution.pdf to Annexure_B6_ Braille-Booklet-on-Plastic-Pollution.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Chunk by chunk\n",
        "prompt = [\"This article is published by who?\", \"Who are the group members of this?\"] #@param {type:\"raw\"}\n",
        "method = \"split_by_sentence\" #@param [\"split_by_smaller_chunks\", \"split_by_sentence\", \"split_by_paragraph\"]\n",
        "MAX_TOKENS_PER_REQUEST = 4000 #@param {type:\"number\"}\n",
        "j = \" \"\n",
        "joined_prompt = j.join(prompt)\n",
        "method = \"split_by_sentence\"\n",
        "keywords_text = \"Generate keywords of following text.\" + \"\\nText: \" + joined_prompt\n",
        "keywords = openai_response(keywords_text)\n",
        "\n",
        "results = generate_response_2(text, prompt, keywords, method, MAX_TOKENS_PER_REQUEST)\n",
        "\n",
        "# join outputs\n",
        "s = \"\\n\"\n",
        "results = s.join(results)\n",
        "\n",
        "data = {}\n",
        "for p_text in prompt:\n",
        "  # Concatenate the input chunk and prompt into a single string\n",
        "  context = p_text + \"\\nText: \" + results\n",
        "\n",
        "  # Generate the output using the GPT-3 API\n",
        "  response = openai_response(context)\n",
        "  res = response.choices[0].text.strip()\n",
        "  data[p_text] = res\n",
        "for key, val in data.items():\n",
        "  print(f\"{key}: {val}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "3On7m9Y3QqMx",
        "outputId": "fa7aeadb-7300-4f33-fb6c-925cd74ff571"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This article is published by who?: This article is published by the Energy and Resources Institute (TERI) and sponsored by the United Nations Environment Programme (UNEP).\n",
            "Who are the group members of this?: The group members for this publication are Dr. Anjali Parasnis, Ms. Vaishnavi Barthwal, Mr. Manish Asodekar, Ms. Pranali Chavan and Mr. Prakash Joshi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"exp_results.json\", \"w\") as outfile:\n",
        "    json.dump(data, outfile, indent=4)"
      ],
      "metadata": {
        "id": "mc_B1LVyVkuC"
      },
      "execution_count": 75,
      "outputs": []
    }
  ]
}